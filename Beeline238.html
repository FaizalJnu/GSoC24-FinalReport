<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GSOC End-Term Report</title>
    <link rel="stylesheet" href="Beeline238.css">
</head>
<body>
    <div class="section" id="introduction">
        <h1>NRNB <strong>Issue-238</strong></h1>
        <h2>A short description of the goals of the project</h2>
        <p>The primary goal of this project was to establish a framework for evaluating the performance of foundation models, specifically scGPT, in generating embeddings suitable for gene regulatory network (GRN) inference. By leveraging the BEELINE benchmark, we aimed to create a standardized approach for assessing the effectiveness of current and future foundational models in the context of GRN inference.</p>
    </div>
    <div class="section" id="what-i-did">
        <h2>What I Did</h2>
        <ul class="styled-list">
            <li>Implementing a pipeline to use scGPT for generating embeddings from single-cell RNA sequencing data.</li>
            <li>Integrating these embeddings within the BEELINE benchmark to evaluate their effectiveness in GRN inference.</li>
            <li>Comparing the performance of scGPT-generated embeddings against traditional methods used in GRN inference.</li>
            <li>Developing metrics and visualization tools to quantify and illustrate the performance of scGPT in this context.</li>
        </ul>
    </div>
    <!-- The Current State Section -->
    <div class="section" id="current-state">
        <h2>The Current State</h2>
        <p>All the goals mentioned in the project have been achieved. The model used in this is called <strong>scGPT</strong> (scRNA-seq Generative Pre-trained Transformer) is a relatively new model introduced in a paper in <em>Nature Methods</em> in February 2024, aiming to be a foundation model for single-cell RNA-seq (scRNA-seq) analysis. The authors of scGPT envision pre-trained foundation models furthering the understanding of cellular biology. It leverages the power of generative pre-trained transformers to learn meaningful biological insights from scRNA sequences and it can predict or analyze aspects of scRNA-seq data.</p>

        <p>ScGPT is trained on a large corpus of scRNA-seq from CELLxGENE collection. The exact size of the pre-training dataset is around 33 million cells as explicitly mentioned in the current research. From which 97% was used for training and 3% for testing.</p>

        <p>The model files and embeddings generation pipeline has been added directly into the Beeline framework, that was earlier using expression data, to now being able to use embeddings data with an addition of a simple flag (<code>--use_embeddings</code>) to run the pipeline on generating and using embeddings data for GRN inference.</p>
    </div>
    <!-- What's Left to Do Section -->
    <div class="section" id="whats-left-to-do">
        <h2>What's Left to Do</h2>
        <ul class="simple-list">
            <li>Work on EPr issue is required. According to the BEELINE research paper, the EPr (Early Precision Recall) metric was turning out to be from a scale of 0-7.5, whereas from our computation, the score was turning out to be less than 0.1 in all gene embeddings and gene expression evaluations.</li>
            <li>Hep Datasets, when used for GRN inference, are producing nan values in the case of PIDC algorithms in the gene expression data. This occurs when the preprocessing is done as defined in the paper, using TFs (Transcription factor genes) + 500 genes based on the highest variance scores. However, when only the top 500 genes are chosen without considering any TFs, we get values other than nan in the case of the PIDC algorithm.</li>
            <li>Expanding the evaluation to include other foundation models like scBERT and Geneformer for a comprehensive comparison.</li>
            <li>Fine-tuning the scGPT model specifically for GRN inference tasks to potentially improve performance.</li>
            <li>Exploring the interpretability of the embeddings generated by scGPT to gain insights into the biological relevance of the learned representations.</li>
            <li>Extending the framework to assess performance across diverse datasets and cell types.</li>
        </ul>
    </div>
    <!-- What Code Got Merged Section -->
    <div class="section" id="what-code-got-merged">
        <h2>What Code Got Merged</h2>
        <p>The code merged is as follows, firstly some changes were made to the <strong>BLRunner.py</strong> script in order to incorporate the <code>–use_embeddings</code> flag, so that when the following command is used:</p>
        <pre><code>python BLRunner.py –config config-files/config.yaml –use_embeddings</code></pre>
        <p>The change made in this file was:</p>
        <ol class="code-list">
            <li>In the <strong>get_parser()</strong> function:
                <pre><code>parser.add_argument('--use_embeddings', action='store_true',
        help='Use embeddings for expression data')</code></pre>
            </li>
            <li>In the <strong>main()</strong> function:
                <pre><code>for idx in range(len(evaluation.runners)):
        evaluation.runners[idx].use_embeddings = opts.use_embeddings</code></pre>
            </li>
        </ol>
        
        <p>Following this, some additions were made in the <strong>runner.py</strong> file in the <strong>BLRun</strong> class:</p>
        <ol class="code-list">
            <li>In the <strong>Runner</strong> class:
                <pre><code>self.use_embeddings = params.get('use_embeddings', False)
    self.embeddings_file = None</code></pre>
            </li>
            <li>Function added in the <strong>Runner</strong> class:
                <pre><code>def generate_embeddings(self):
        embed_script_path = Path(__file__).resolve().parent / "generate_embeds.py"
        
        if not embed_script_path.exists():
            raise FileNotFoundError(f"Embeddings script not found at {embed_script_path}")
        
        expr_filename = Path(self.exprData).stem
        new_input_dir = Path(self.inputDir) / f"processed_{expr_filename}"
        new_input_dir.mkdir(parents=True, exist_ok=True)
        
        self.embeddings_file = new_input_dir / "EmbeddingsData.csv"
        
        print(f"Using input file: {self.exprData}")
        print(f"Running embedding generation script at: {embed_script_path}")
        print(f"Embeddings will be saved to: {self.embeddings_file}")
        
        command = [
            "python",
            str(embed_script_path),
            "--input", str(Path(self.inputDir) / self.exprData),
        ]
        
        try:
            subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            print("Embeddings generated successfully.")
            
            generated_file = Path(self.inputDir) / "EmbeddingsData.csv"
            if generated_file.exists():
                shutil.move(str(generated_file), str(self.embeddings_file))
                print(f"Embeddings moved to {self.embeddings_file}")
            
            ref_network_file = Path(self.inputDir) / "refNetwork.csv"
            if ref_network_file.exists():
                shutil.copy(str(ref_network_file), str(new_input_dir))
                print(f"refNetwork.csv copied to {new_input_dir}")
            else:
                print("refNetwork.csv not found in the input directory.")
            
            self.inputDir = new_input_dir
            self.exprData = "EmbeddingsData.csv"
            
        except subprocess.CalledProcessError as e:
            print(f"Error generating embeddings: {e}")
            print(f"Script output: {e.output.decode()}")
            print(f"Script error: {e.stderr.decode()}")
            raise</code></pre>
            </li>
        </ol>
        
        <p>This will ensure that the <strong>generate_embeds.py</strong> script is called within the same <strong>BLRun</strong> class if the flag is used, and the right input and output directories are passed on. The <strong>generate_embeds.py</strong> file is another addition I have made entirely:</p>
        <pre><code>import subprocess
    import os
    import argparse

    def generate_embeddings(input_file):
        input_dir = os.path.dirname(os.path.abspath(input_file))
        print("------>", input_dir)
        input_filename = os.path.basename(input_file)
        
        output_file = os.path.join(input_dir, "EmbeddingsData.csv")

        cmd = [
            "docker", "run", "--rm",
            "-v", f"{input_dir}:/input", 
            "scgpt_human",  
            "--input", f"/input/{input_filename}", 
            "--model_dir", "/app" 
        ]
        
        try:
            subprocess.run(cmd, check=True)
            print(f"Embeddings generated successfully. Output saved to {output_file}")
        except subprocess.CalledProcessError as e:
            print(f"Error generating embeddings: {e}")
            raise

    def main():
        parser = argparse.ArgumentParser(description='Generate gene embeddings using scGPT model')
        parser.add_argument('--input', required=True, help='Path to input expression data CSV file')
        
        args = parser.parse_args()
        
        generate_embeddings(args.input)

    if __name__ == "__main__":
        main()</code></pre>
        
        <p>The pipeline automatically generates embeddings and uses them for GRN Inference. The whole pipeline here uses a <strong>generate_embeddings.py</strong> and model files located in another addition made here in a directory named <strong>Model</strong>. The model files and generate_embeddings script have been entirely dockerized.</p>
        
        <p><strong>generate_embeddings.py</strong> script:</p>
        <pre><code>import pandas as pd
    import json
    import warnings
    import torch
    from scgpt.tokenizer.gene_tokenizer import GeneVocab
    from scgpt.model import TransformerModel
    from scgpt.utils import set_seed
    import os
    import argparse

    warnings.filterwarnings('ignore')
    set_seed(42)

    def initialize_model(args_file, model_file, vocab_file):
        if not all(os.path.exists(f) for f in [args_file, model_file, vocab_file]):
            raise FileNotFoundError(f"Required model files not found: {args_file, model_file, vocab_file}")

        vocab = GeneVocab.from_file(vocab_file)
        special_tokens = ["<pad>", "<cls>", "<eoc>"]
        for s in special_tokens:
            if s not in vocab, vocab.append_token(s)
        
        with open(args_file, "r") as f:
            model_configs = json.load(f)
        
        ntokens = len(vocab)
        model = TransformerModel(
            ntokens,
            model_configs["embsize"],
            model_configs["nheads"],
            model_configs["d_hid"],
            model_configs["nlayers"],
            vocab=vocab,
            pad_value=model_configs.get("pad_value", -2),
            n_input_bins=model_configs.get("n_bins", 51),
        )
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        state_dict = torch.load(model_file, map_location=device)
        
        model.load_state_dict(state_dict, strict=False)
        model.to(device)
        model.eval()
        
        return model, vocab, device

    def generate_and_save_embeddings(file_path, model, vocab, device, output_file):
        expression_data = pd.read_csv(file_path, index_col=0)
        gene_names = expression_data.index.tolist()
        tokenized_genes = []
        for gene in gene_names:
            upper_gene = gene.upper()
            if upper_gene in vocab:
                tokenized_genes.append(vocab[upper_gene])
            else:
                tokenized_genes.append(vocab["<pad>"])  # Use <pad> token for unknown genes

        gene_ids = torch.tensor(tokenized_genes, dtype=torch.long).to(device)
        with torch.no_grad():
            gene_embeddings = model.encoder(gene_ids)
        gene_embeddings = gene_embeddings.detach().cpu().numpy()
        
        gene_embeddings_dict = {gene: gene_embeddings[i] for i, gene in enumerate(gene_names)}
        embeddings_df = pd.DataFrame(gene_embeddings_dict).T
        embeddings_df.to_csv(output_file)
        print(f'Saved gene embeddings for {len(gene_embeddings_dict)} genes to {output_file}')

    if __name__ == "__main__":
        parser = argparse.ArgumentParser(description='Generate gene embeddings')
        parser.add_argument('--input', required=True, help='Path to input expression data CSV file')
        parser.add_argument('--model_dir', default='/app', help='Directory containing model files')
        args = parser.parse_args()

        # Generate output path based on input path
        input_dir = os.path.dirname(args.input)
        input_filename = os.path.basename(args.input)
        output_filename = "EmbeddingsData.csv"
        output_path = os.path.join(input_dir, output_filename)
        
        print("Debug Information:")
        print(f"Input file path: {args.input}")
        print(f"Output file path: {output_path}")
        print(f"Model directory: {args.model_dir}")

        args_file = os.path.join(args.model_dir, "args.json")
        model_file = os.path.join(args.model_dir, "best_model.pt")
        vocab_file = os.path.join(args.model_dir, "vocab.json")

        try:
            model, vocab, device = initialize_model(args_file, model_file, vocab_file)
            generate_and_save_embeddings(args.input, model, vocab, device, output_path)
        except FileNotFoundError as e:
            print(f"Error: {e}")
            print("Please ensure that the model files (args.json, best_model.pt, vocab.json) are in the correct directory.")
            print(f"Current model directory: {args.model_dir}")
            exit(1)</code></pre>
        
        <p>Another additional change I made that was essential to fast pace the evaluation pipeline was a small change in the <strong>computeScores()</strong> function in the <strong>computeDGAUC.py</strong> file in the BLEval folder.</p>
        <pre><code># Get unique genes
    unique_genes = np.unique(trueEdgesDF.loc[:, ['Gene1', 'Gene2']])
        
    # Convert DataFrames to dictionaries for faster lookup
    true_edges = set(map(tuple, trueEdgesDF[['Gene1', 'Gene2']].values))
    pred_edges = dict(zip(map(tuple, predEdgeDF[['Gene1', 'Gene2']].values), 
                        predEdgeDF['EdgeWeight']))

    TrueEdgeDict = {}
    PredEdgeDict = {}

    if directed:
        edge_generator = product(unique_genes, repeat=2) if selfEdges else permutations(unique_genes, r=2)
    else:
        edge_generator = combinations_with_replacement(unique_genes, r=2) if selfEdges else combinations(unique_genes, r=2)

    for edge in edge_generator:
        key = '|'.join(edge)
        
        # Compute TrueEdgeDict
        TrueEdgeDict[key] = int(edge in true_edges or (not directed and edge[::-1] in true_edges))
        
        # Compute PredEdgeDict
        if directed:
            PredEdgeDict[key] = abs(pred_edges.get(edge, 0))
        else:
            PredEdgeDict[key] = max(abs(pred_edges.get(edge, 0)), abs(pred_edges.get(edge[::-1], 0)))</code></pre>
        
        <p>The <strong>computeScores</strong> function has been optimized for improved performance and efficiency. Key enhancements include:</p>
        <ul class="styled-list">
            <li><strong>Efficient Data Structures:</strong> Converted input DataFrames to sets and dictionaries for faster edge lookups.</li>
            <li><strong>Streamlined Edge Generation:</strong> Unified the logic for generating possible edges in both directed and undirected cases.</li>
            <li><strong>On-the-Fly Dictionary Creation:</strong> Eliminated the need for pre-initializing dictionaries with all possible edges.</li>
            <li><strong>Concise Code Structure:</strong> Reduced code repetition, particularly in handling directed and undirected cases.</li>
            <li><strong>Performance Implications:</strong> Expected significant speed improvements, especially for large genetic networks.</li>
            <li><strong>Scalability:</strong> Better suited for handling large-scale genetic network data.</li>
        </ul>
    </div>

    <!-- Important Things I Learned During the Project Section -->
    <div class="section" id="important-lessons">
        <h2>Important Things I Learned During the Project</h2>
        <ul class="simple-list">
            <li>Adapting language model architectures to biological data required a deep understanding of both machine learning and genomics.</li>
            <li>Balancing computational efficiency with model performance was crucial, especially when dealing with large-scale single-cell datasets.</li>
            <li>Interpreting the biological significance of embeddings generated by foundation models proved to be a complex task, highlighting the need for interdisciplinary approaches.</li>
            <li>The importance of rigorous benchmarking in computational biology, as demonstrated by the BEELINE framework, became evident throughout the project.</li>
            <li>Collaborating with researchers from diverse backgrounds enhanced the project's scope and impact, emphasizing the value of interdisciplinary work in bioinformatics.</li>
        </ul>
    </div>


</body>
</html>
